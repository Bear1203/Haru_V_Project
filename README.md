# 學習Vtuber製作
## 本作品介紹
  為了記錄學習研究內容，分享研究內容和充實作品集而打此篇GitHub。此作品功能為
1. 取得人的即時頭部姿勢(頭抬低、頭左右轉、頭左右傾)，取得人的即時臉部狀態(眼睛開合、視線追蹤、嘴巴開合)，將這些資料傳送給 Unity 接收端。`HaruConnect/haru_connect.py`
2. 接收資料並即時同步 Unity 角色狀態。`Haru Vtuber`
## 使用工具
| 工具 | 簡介 |
| --- | --- |
| [ANACONDA](https://www.anaconda.com/products/individual) | 虛擬環境 |
| [VS CODE](https://code.visualstudio.com/) | 程式碼編輯器 |
| [LIVE 2D](https://www.live2d.com/) | live2D 角色製作，本作品使用免費素材角色 |
| [UNITY](https://unity.com/) | Live2D 角色使用 |
| [OBS STUDIO](https://obsproject.com/) | 螢幕擷取與直播串流 |
## 本作品使用步驟
1. 先將'FaceModel.zip'裡的人臉預測模型，放入`Haru_exe`與`HaruConnect`資料夾中。
2. 確保電腦有一個鏡頭。
3. 先點擊`Haru_exe/Haru Vtuber.exe`，再點擊`Haru_exe/haru_connect.exe`。
4. 沒意外的話就能使用了。
5. 可與直播軟體擷取`Haru Vtuber.exe`畫面，搭配綠幕去背使用。
6. 盡量保持頭在鏡頭視窗內，不要太遠或太近，一開始請調整鏡頭照到臉時為臉部正面。
# :bowtie::laughing:謝謝閱讀:laughing::bowtie:
### P.S. 只是單純使用沒要看程式，最後保留`Haru_exe`資料夾就可以了:relieved:。
### P.S. 也許之後有時間會再更新:relieved:。
